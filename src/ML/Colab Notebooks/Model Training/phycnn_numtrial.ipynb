{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"phycnn_numtrial.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzjjj3wuztiL","executionInfo":{"status":"ok","timestamp":1628355792694,"user_tz":-330,"elapsed":5110,"user":{"displayName":"Aswin Suresh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQeczr1lOBtHfvynTQ1T2ODPQ9nMYG42X4O9eh=s64","userId":"06795276616388232599"}},"outputId":"e32d70fe-b1d5-4fa4-efc8-94aba9caabd4"},"source":["%tensorflow_version 1.x\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","1.15.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVDC5ZDSLXkr","executionInfo":{"status":"ok","timestamp":1628355816961,"user_tz":-330,"elapsed":22545,"user":{"displayName":"Aswin Suresh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQeczr1lOBtHfvynTQ1T2ODPQ9nMYG42X4O9eh=s64","userId":"06795276616388232599"}},"outputId":"f2584833-919a-42cc-a079-e72f9293bb8e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpiODfuWHFoq","executionInfo":{"status":"ok","timestamp":1628355820571,"user_tz":-330,"elapsed":966,"user":{"displayName":"Aswin Suresh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQeczr1lOBtHfvynTQ1T2ODPQ9nMYG42X4O9eh=s64","userId":"06795276616388232599"}},"outputId":"c4b45e1d-ecb1-44e3-e97c-5cb09459779a"},"source":["\"\"\"\n","@author: Ruiyang Zhang\n","\"\"\"\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dropout, Dense\n","from keras.optimizers import RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam, SGD\n","from keras.layers import Conv1D, Flatten, LSTM, Reshape, BatchNormalization, Activation, UpSampling1D, ZeroPadding1D, PReLU\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LinearRegression\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io\n","import time\n","import os\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # CPU:-1; GPU0: 1; GPU1: 0;"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L-nOecfPPG8V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"18tBtieE8PfAJewi3-xKjUZAudRs6GRfw"},"id":"zSk9FgQ2Lb-k","executionInfo":{"status":"ok","timestamp":1628356609485,"user_tz":-330,"elapsed":785419,"user":{"displayName":"Aswin Suresh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQeczr1lOBtHfvynTQ1T2ODPQ9nMYG42X4O9eh=s64","userId":"06795276616388232599"}},"outputId":"597b913a-f982-4169-e6ce-34f643e18250"},"source":["class DeepPhyLSTM:\n","    # Initialize the class\n","    def __init__(self, eta_tt, ag, Phi_t):\n","\n","        # data\n","        self.eta_tt = eta_tt\n","        self.ag = ag\n","        # self.lift = lift\n","        # self.ag_c = ag_c\n","        self.Phi_t = Phi_t\n","        # self.Phi_tt = Phi_tt\n","\n","        # tf placeholders and graph\n","        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n","                                                     log_device_placement=True))\n","        \n","        # placeholders for data\n","        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n","        # self.eta_tf = tf.placeholder(tf.float32, shape=[None, None, self.eta.shape[2]])\n","        # self.eta_t_tf = tf.placeholder(tf.float32, shape=[None, None, self.eta.shape[2]])\n","        self.eta_tt_tf = tf.placeholder(tf.float32, shape=[None, None, 1])\n","        self.ag_tf = tf.placeholder(tf.float32, shape=[None, None, 1])\n","\n","        # physics informed neural networks\n","        self.eta_pred, self.eta_t_pred, self.eta_tt_pred, = self.net_structure(self.ag_tf)\n","\n","        # loss\n","        # for measurements\n","        self.loss = tf.reduce_mean(tf.square(self.eta_tt_tf - self.eta_tt_pred)) + tf.reduce_mean(tf.square(self.eta_pred[:,:,0:10]))\n","\n","        # optimizers\n","        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss,\n","                                                                method='L-BFGS-B',\n","                                                                options={'maxiter': 20000,\n","                                                                         'maxfun': 50000,\n","                                                                         'maxcor': 50,\n","                                                                         'maxls': 50,\n","                                                                         'ftol': 1 * np.finfo(float).eps})\n","\n","        self.optimizer_Adam = tf.train.AdamOptimizer(learning_rate = self.learning_rate)\n","        self.train_op = self.optimizer_Adam.minimize(self.loss)\n","\n","        init = tf.global_variables_initializer()\n","        self.sess.run(init)\n","\n","    def CNN_model(self, X):\n","        model = Sequential()\n","        model.add(Conv1D(64, 50, strides=1, padding='same', use_bias=True, input_shape=(None, 1)))\n","        model.add(Activation('relu'))\n","        model.add(Conv1D(64, 50, strides=1, padding='same', use_bias=True))\n","        model.add(Activation('relu'))\n","        model.add(Conv1D(64, 50, strides=1, padding='same', use_bias=True))\n","        model.add(Activation('relu'))\n","        model.add(Conv1D(64, 50, strides=1, padding='same', use_bias=True))\n","        model.add(Activation('relu'))\n","        model.add(Conv1D(64, 50, strides=1, padding='same', use_bias=True))\n","        model.add(Activation('relu'))\n","        model.add(Dense(50))\n","        model.add(Activation('relu'))\n","        model.add(Dense(50))\n","        model.add(Activation('relu'))\n","        model.add(Dense(self.eta_tt.shape[2]))\n","        y = model(X)\n","        return y\n","\n","    def net_structure(self, ag):\n","        eta = self.CNN_model(ag)\n","\n","        Phi_ut = np.reshape(self.Phi_t, [1, self.eta_tt.shape[1], self.eta_tt.shape[1]])\n","        Phi_ut = np.repeat(Phi_ut, self.eta_tt.shape[0], axis=0)\n","        eta_t = tf.matmul(tf.cast(Phi_ut, dtype=tf.float32), eta)\n","        eta_tt = tf.matmul(tf.cast(Phi_ut, dtype=tf.float32), eta_t)\n","\n","        return eta, eta_t, eta_tt\n","    \n","    def train(self, num_epochs, batch_size, learning_rate, bfgs):\n","\n","        Loss = []\n","\n","        for epoch in range(num_epochs):\n","            \n","            N = self.eta_tt.shape[0]\n","\n","            start_time = time.time()\n","            for it in range(0, N, batch_size):\n","                tf_dict = {self.eta_tt_tf: self.eta_tt, self.ag_tf: self.ag, self.learning_rate: learning_rate}\n","                self.sess.run(self.train_op, tf_dict)\n","                \n","                # Print\n","                if it % (10*batch_size) == 0:\n","                    elapsed = time.time() - start_time\n","                    loss_value, learning_rate_value = self.sess.run([self.loss, self.learning_rate], tf_dict)\n","                    print('Epoch: %d, It: %d, Loss: %.3e, Time: %.2f, Learning Rate: %.3e'\n","                          %(epoch, it/batch_size, loss_value, elapsed, learning_rate_value))\n","                    start_time = time.time()\n","\n","            Loss.append(self.sess.run(self.loss, tf_dict))\n","\n","        if bfgs == 1:\n","            tf_dict_all = {self.eta_tt_tf: self.eta_tt, self.ag_tf: self.ag, self.learning_rate: learning_rate}\n","\n","            self.optimizer.minimize(self.sess,\n","                                    feed_dict=tf_dict_all,\n","                                    fetches=[self.loss],\n","                                    loss_callback=self.callback)\n","\n","            Loss.append(self.sess.run(self.loss, tf_dict))\n","\n","        return Loss\n","\n","    def callback(self, loss):\n","        print('Loss:', loss)\n","\n","    def predict(self, ag_star):\n","        \n","        tf_dict = {self.ag_tf: ag_star}\n","\n","        eta_star = self.sess.run(self.eta_pred, tf_dict)\n","        eta_t_star = self.sess.run(self.eta_t_pred, tf_dict)\n","        eta_tt_star = self.sess.run(self.eta_tt_pred, tf_dict)\n","\n","        return eta_star, eta_t_star, eta_tt_star\n","    \n","if __name__ == \"__main__\":\n","\n","    # load data\n","    dataDir = \"/content/drive/MyDrive/Mini Project- AG2RS1-6.0/New/Data/phy/\"\n","    mat = scipy.io.loadmat(dataDir + 'data_num.mat')\n","\n","    ag_data = mat['input_tf']  # ag, ad, av\n","    u_data = mat['target_X_tf']\n","    ut_data = mat['target_Xd_tf']\n","    utt_data = mat['target_Xdd_tf']\n","    ag_data = ag_data.reshape([ag_data.shape[0], ag_data.shape[1], 1])\n","    u_data = u_data.reshape([u_data.shape[0], u_data.shape[1], 1])\n","    ut_data = ut_data.reshape([ut_data.shape[0], ut_data.shape[1], 1])\n","    utt_data = utt_data.reshape([utt_data.shape[0], utt_data.shape[1], 1])\n","\n","    t = mat['time']\n","    dt = t[0, 1] - t[0, 0]\n","\n","    ag_all = ag_data\n","    u_all = u_data\n","    u_t_all = ut_data\n","    u_tt_all = utt_data\n","\n","    # finite difference\n","    n = u_data.shape[1]\n","    phi1 = np.concatenate([np.array([-3 / 2, 2, -1 / 2]), np.zeros([n - 3, ])])\n","    temp1 = np.concatenate([-1 / 2 * np.identity(n - 2), np.zeros([n - 2, 2])], axis=1)\n","    temp2 = np.concatenate([np.zeros([n - 2, 2]), 1 / 2 * np.identity(n - 2)], axis=1)\n","    phi2 = temp1 + temp2\n","    phi3 = np.concatenate([np.zeros([n - 3, ]), np.array([1 / 2, -2, 3 / 2])])\n","    Phi_t = 1 / dt * np.concatenate(\n","            [np.reshape(phi1, [1, phi1.shape[0]]), phi2, np.reshape(phi3, [1, phi3.shape[0]])], axis=0)\n","\n","    ag_star = ag_all[0:50]\n","    eta_star = u_all[0:50]\n","    eta_t_star = u_t_all[0:50]\n","    eta_tt_star = u_tt_all[0:50]\n","    g_star = -eta_tt_star -ag_star\n","    lift_star = -ag_star\n","\n","    N_train = eta_star.shape[0]\n","\n","    eta = eta_star\n","    ag = ag_star\n","    lift = lift_star\n","    eta_t = eta_t_star\n","    eta_tt = eta_tt_star\n","    g = g_star\n","\n","    # Training Data\n","    eta_train = eta\n","    ag_train = ag\n","    lift_train = lift\n","    eta_t_train = eta_t\n","    eta_tt_train = eta_tt\n","    g_train = g\n","\n","\n","with tf.device('/device:GPU:0'):\n","    # with tf.device('/cpu:0'):\n","\n","    config = tf.ConfigProto()\n","    config.gpu_options.allow_growth = True\n","    # config.gpu_options.per_process_gpu_memory_fraction = 0.4\n","    session = tf.Session(config=config)\n","    # tf.Session(config=tf.ConfigProto(log_device_placement=True))\n","\n","    # Training\n","    model = DeepPhyLSTM(eta_tt_train, ag_train, Phi_t)\n","\n","    train_loss = model.train(num_epochs=10000, batch_size=N_train, learning_rate=1e-3, bfgs=1)\n"," \n","    plt.figure()\n","    plt.plot(np.log(train_loss), label='loss')\n","    # plt.plot(np.log(test_loss), label='loss_val')\n","    plt.legend()\n","    # Training performance\n","    X_train = ag_train\n","    y_train_ref = eta_train\n","    yt_train_ref = eta_t_train\n","    ytt_train_ref = eta_tt_train\n","    # g_train_ref = -eta_tt_train-ag_train\n","\n","    # Prediction\n","    eta, eta_t, eta_tt= model.predict(X_train)\n","\n","    y_train_pred = eta\n","    yt_train_pred = eta_t\n","    ytt_train_pred = eta_tt\n","\n","    dof = 0\n","    for n in range(len(ag_star)):\n","        plt.figure()\n","        plt.plot(y_train_ref[n, :, dof], label='True')\n","        plt.plot(y_train_pred[n, :, dof], label='Predict')\n","        plt.title('Training_u')\n","        plt.legend()\n","\n","    for n in range(len(ag_star)):\n","        plt.figure()\n","        plt.plot(yt_train_ref[n, :, dof], label='True')\n","        plt.plot(yt_train_pred[n, :, dof], label='Predict')\n","        plt.title('Training_ut')\n","        plt.legend()\n","\n","    for n in range(len(ag_star)):\n","        plt.figure()\n","        plt.plot(ytt_train_ref[n, :, dof], label='True')\n","        plt.plot(ytt_train_pred[n, :, dof], label='Predict')\n","        plt.title('Training_utt')\n","        plt.legend()\n","\n","    # Prediction performance\n","    ag_pred = np.concatenate([mat['input_tf'], mat['input_pred_tf']])  # ag, ad, av\n","    u_pred = np.concatenate([mat['target_X_tf'], mat['target_pred_X_tf']])\n","    ut_pred = np.concatenate([mat['target_Xd_tf'], mat['target_pred_Xd_tf']])\n","    utt_pred = np.concatenate([mat['target_Xdd_tf'], mat['target_pred_Xdd_tf']])\n","    ag_pred = ag_pred.reshape([ag_pred.shape[0], ag_pred.shape[1], 1])\n","    u_pred = u_pred.reshape([u_pred.shape[0], u_pred.shape[1], 1])\n","    ut_pred = ut_pred.reshape([ut_pred.shape[0], ut_pred.shape[1], 1])\n","    utt_pred = utt_pred.reshape([utt_pred.shape[0], utt_pred.shape[1], 1])\n","\n","    X_pred = ag_pred[50:]\n","    y_pred_ref = u_pred[50:]\n","    yt_pred_ref = ut_pred[50:]\n","    ytt_pred_ref = utt_pred[50:]\n","\n","    Index_train = list(range(0, 50))\n","\n","    # Prediction\n","    n_p = int(np.ceil(len(X_pred) / len(Index_train)))\n","    y_pred = np.zeros(y_pred_ref.shape)\n","    yt_pred = np.zeros(y_pred_ref.shape)\n","    ytt_pred = np.zeros(ytt_pred_ref.shape)\n","    for jj in range(n_p):\n","        ind_str = len(Index_train) * jj\n","        ind_end = len(Index_train) * (jj + 1)\n","        eta, eta_t, eta_tt = model.predict(X_pred[ind_str:ind_end])\n","        y_pred[ind_str:ind_end] = eta\n","        yt_pred[ind_str:ind_end] = eta_t\n","        ytt_pred[ind_str:ind_end] = eta_tt\n","\n","    for ii in range(len(y_pred)):\n","        plt.figure()\n","        plt.plot(y_pred_ref[ii, :, dof], label='True')\n","        plt.plot(y_pred[ii, :, dof], label='Predict')\n","        plt.title('Prediction_u')\n","        plt.legend()\n","\n","        plt.figure()\n","        plt.plot(yt_pred_ref[ii], label='True')\n","        plt.plot(yt_pred[ii], label='Predict')\n","        plt.title('Prediction_u_t')\n","        plt.legend()\n","\n","        plt.figure()\n","        plt.plot(ytt_pred_ref[ii], label='True')\n","        plt.plot(ytt_pred[ii], label='Predict')\n","        plt.title('Prediction_u_tt')\n","        plt.legend()\n","\n","    R1 = []\n","    R2 = []\n","    R3 = []\n","    for ii in range(len(y_pred_ref)):\n","        reg1 = LinearRegression().fit(y_pred_ref[ii, :, 0:1], y_pred[ii, :, 0:1])\n","        R1.append(reg1.coef_)\n","    R = np.concatenate([np.array(R1)])\n","    R = R[:, 0]\n","    plt.hist(R, 'auto', density=True, facecolor='blue', alpha=0.5)\n","    plt.grid(axis='y', alpha=0.75)\n","    plt.xlabel('Value')\n","    plt.ylabel('Frequency')\n","    plt.title('Histogram_Model')\n","    ax = plt.gca()\n","    ax.invert_xaxis()\n"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"shyGzAvIKX5H"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZ3gMyMmPgbf"},"source":[""],"execution_count":null,"outputs":[]}]}